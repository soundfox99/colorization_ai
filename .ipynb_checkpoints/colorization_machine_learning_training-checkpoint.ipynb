{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cafb597e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Folders\n",
    "bw_folder = \"./training_data/filtered_data/Input_2\"\n",
    "color_input_folder = \"./training_data/filtered_data/Input_1\"\n",
    "color_output_folder = \"./training_data/filtered_data/Output\"\n",
    "\n",
    "# List files\n",
    "bw_files = sorted(os.listdir(bw_folder))\n",
    "color_input_files = sorted(os.listdir(color_input_folder))\n",
    "color_output_files = sorted(os.listdir(color_output_folder))\n",
    "\n",
    "# Ensure filenames match\n",
    "assert bw_files == color_input_files == color_output_files, \"Filenames do not match!\"\n",
    "\n",
    "# Split files into training and validation set\n",
    "train_ratio = 0.8\n",
    "bw_train_files, bw_val_files, _, _ = train_test_split(bw_files, bw_files, test_size=1-train_ratio, random_state=42)\n",
    "\n",
    "# Ensure filenames match for training and validation\n",
    "assert set(bw_train_files) & set(bw_val_files) == set(), \"Overlap between training and validation files!\"\n",
    "\n",
    "# Load a batch of images from a list of filenames and folder\n",
    "def load_batch_from_folder(folder, files, start_idx, batch_size, color=True):\n",
    "    images = []\n",
    "    end_idx = min(start_idx + batch_size, len(files))\n",
    "    \n",
    "    for i in range(start_idx, end_idx):\n",
    "        img_path = os.path.join(folder, files[i])\n",
    "        if color:\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "            #img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        else:\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            img = np.expand_dims(img, axis=-1)  # Add channel dimension\n",
    "        img = img / 255.0\n",
    "        images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "# Separate generators for training and validation\n",
    "def image_data_generator(files, batch_size):\n",
    "    total_images = len(files)\n",
    "    while True:\n",
    "        for start_idx in range(0, total_images, batch_size):\n",
    "            bw_batch = load_batch_from_folder(bw_folder, files, start_idx, batch_size, color=False)\n",
    "            color_input_batch = load_batch_from_folder(color_input_folder, files, start_idx, batch_size)\n",
    "            color_output_batch = load_batch_from_folder(color_output_folder, files, start_idx, batch_size)\n",
    "            yield ([bw_batch, color_input_batch], color_output_batch)\n",
    "\n",
    "# Example of usage\n",
    "batch_size = 32\n",
    "train_generator = image_data_generator(bw_train_files, batch_size)\n",
    "val_generator = image_data_generator(bw_val_files, batch_size)\n",
    "\n",
    "# for input_batch, output_batch in train_generator:\n",
    "#     print('Train:', input_batch[0].shape, input_batch[1].shape, output_batch.shape)\n",
    "\n",
    "# for bw_batch, color_input_batch, color_output_batch in val_generator:\n",
    "#     print('Validation:', bw_batch.shape, color_input_batch.shape, color_output_batch.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "659cf65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# batch_size = 32\n",
    "\n",
    "# # Data Augmentation\n",
    "# datagen = ImageDataGenerator(\n",
    "#     rotation_range=20,\n",
    "#     zoom_range=0.15,\n",
    "#     width_shift_range=0.2,\n",
    "#     height_shift_range=0.2,\n",
    "#     shear_range=0.15,\n",
    "#     horizontal_flip=True,\n",
    "#     fill_mode=\"nearest\"\n",
    "# )\n",
    "\n",
    "# # Generator for augmented data\n",
    "# def augmented_data_generator(batch_size):\n",
    "#     base_generator = image_data_generator(batch_size)\n",
    "    \n",
    "#     for bw_batch, color_input_batch, color_output_batch in base_generator:\n",
    "#         # Augment each batch\n",
    "#         # Note: We're using the same seed for both black & white and color input images\n",
    "#         # to ensure they undergo the same transformations.\n",
    "        \n",
    "#         # Augmenting BW images\n",
    "#         bw_gen = datagen.flow(bw_batch, batch_size=batch_size, shuffle=False, seed=42)\n",
    "        \n",
    "#         # Augmenting color input images\n",
    "#         color_input_gen = datagen.flow(color_input_batch, batch_size=batch_size, shuffle=False, seed=42)\n",
    "        \n",
    "#         # Augmenting color output images. Since we need to match outputs with inputs, \n",
    "#         # we're not shuffling and using a consistent seed.\n",
    "#         color_output_gen = datagen.flow(color_output_batch, batch_size=batch_size, shuffle=False, seed=42)\n",
    "        \n",
    "#         yield [next(bw_gen), next(color_input_gen)], next(color_output_gen)\n",
    "\n",
    "# # Example of usage\n",
    "# aug_gen = augmented_data_generator(batch_size)\n",
    "# for (bw_aug_batch, color_input_aug_batch), color_output_aug_batch in aug_gen:\n",
    "#     print(bw_aug_batch.shape, color_input_aug_batch.shape, color_output_aug_batch.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52438ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, Concatenate, MaxPooling2D\n",
    "\n",
    "def DualInput():\n",
    "    # Black & white input\n",
    "    bw_input = Input(shape=(2048, 1400, 1))\n",
    "#     bw_layer1 = Conv2D(8, (3, 3), activation='relu', padding='same', strides=2)(bw_input)\n",
    "#     bw_layer2 = MaxPooling2D((2, 2))(bw_layer1)\n",
    "    \n",
    "    # Colored reference input\n",
    "    color_input = Input(shape=(2048, 1400, 3))\n",
    "#     color_input1 = Conv2D(8, (3, 3), activation='relu', padding='same', strides=2)(color_input)\n",
    "#     color_input2 = MaxPooling2D((2, 2))(color_input1)\n",
    "\n",
    "    # Merge inputs\n",
    "    merge_layer = Concatenate()([bw_input, color_input]) # This will have 4 channels\n",
    "\n",
    "    # Output layer to produce a 3-channel image\n",
    "    outputs = Conv2D(3, (1, 1), activation='linear')(merge_layer)\n",
    "\n",
    "    return tf.keras.Model(inputs=[bw_input, color_input], outputs=outputs)\n",
    "\n",
    "model = DualInput()\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "859f18bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6036a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.0338 - accuracy: 0.3377\n",
      "Epoch 1: saving model to ./checkpoints/2023_08_15-18_09_42\\cp_2023_08_15-18_09_42.ckpt\n",
      "200/200 [==============================] - 1434s 7s/step - loss: 0.0338 - accuracy: 0.3377 - val_loss: 0.0178 - val_accuracy: 0.3104\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.0163 - accuracy: 0.3504\n",
      "Epoch 2: saving model to ./checkpoints/2023_08_15-18_09_42\\cp_2023_08_15-18_09_42.ckpt\n",
      "200/200 [==============================] - 1438s 7s/step - loss: 0.0163 - accuracy: 0.3504 - val_loss: 0.0147 - val_accuracy: 0.3721\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.0137 - accuracy: 0.3770\n",
      "Epoch 3: saving model to ./checkpoints/2023_08_15-18_09_42\\cp_2023_08_15-18_09_42.ckpt\n",
      "200/200 [==============================] - 1384s 7s/step - loss: 0.0137 - accuracy: 0.3770 - val_loss: 0.0126 - val_accuracy: 0.3752\n",
      "Epoch 4/5\n",
      " 36/200 [====>.........................] - ETA: 15:30 - loss: 0.0127 - accuracy: 0.3768"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import datetime\n",
    "steps_per_epoch = math.ceil(len(bw_train_files) / batch_size)\n",
    "validation_steps = math.ceil(len(bw_val_files) / batch_size)\n",
    " \n",
    "time = datetime.datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\")\n",
    "log_dir = \"./logs/fit/\" + time\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "checkpoint_path = f\"./checkpoints/{time}/cp_{time}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "earlystop_callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=2, verbose=1)\n",
    "\n",
    "# 3. Train the model\n",
    "with tf.device('/GPU:0'):\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        validation_data=val_generator,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        validation_steps=validation_steps,\n",
    "        epochs=10,\n",
    "        verbose=1,\n",
    "        callbacks=[tensorboard_callback, cp_callback, earlystop_callback]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d7a825",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = \"./models\"\n",
    "# Save the entire model as a `.keras` zip archive.\n",
    "model.save(f'{model_save_path}/model_{time}.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb12888",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
